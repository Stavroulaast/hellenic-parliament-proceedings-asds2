{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a33358e8-37a6-44e3-9982-1513835cc30e",
   "metadata": {},
   "source": [
    "## ğŸ“’01 | RQ1 Sentinent Discionary Based Analysis using 6 Sentiment Lexicon (Dritsa, 2018)\n",
    "\n",
    "**Preprocessing steps specifically tailored for this analysis:**\\\n",
    "âœ… diacritics removal\\\n",
    "âœ… formal phrases and honorifics\\\n",
    "âœ… remove extra white space\\\n",
    "âœ… tokenize speech\\\n",
    "âœ… lemmatize speech\\\n",
    "âŒ keep stop-words because included in Drista 2018 6 sentiments lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e699f6bc-415d-4490-b174-4e170fb6c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import jellyfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "460525fa-23e3-45dc-99bb-50e6a5aa39ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af7304c5-2ab0-428c-990e-8d0c1cb1a8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rq1_df = pd.read_csv('processed01_par10-20.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce325fc-3721-4cfb-b648-7e5abefbaaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 341805 entries, 0 to 341804\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   Unnamed: 0        341805 non-null  int64 \n",
      " 1   member_name       341805 non-null  object\n",
      " 2   sitting_date      341805 non-null  object\n",
      " 3   political_party   341805 non-null  object\n",
      " 4   government        341805 non-null  object\n",
      " 5   roles             341805 non-null  object\n",
      " 6   member_gender     341805 non-null  object\n",
      " 7   speech            341805 non-null  object\n",
      " 8   year              341805 non-null  int64 \n",
      " 9   is_government     341805 non-null  int64 \n",
      " 10  speaker_gov_role  60473 non-null   object\n",
      " 11  leadership_role   10689 non-null   object\n",
      " 12  speech_clean      338501 non-null  object\n",
      "dtypes: int64(3), object(10)\n",
      "memory usage: 36.5+ MB\n"
     ]
    }
   ],
   "source": [
    "rq1_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc6a117-af94-47ea-a752-f2ee192d2e7f",
   "metadata": {},
   "source": [
    "Tokenization and lemmatization of Greek text using spaCy; whitespace tokens excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6946b4e3-6a26-4f66-b0f0-b5f9d9f8d6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"el_core_news_sm\")\n",
    "\n",
    "def tokenize_and_lemmatize(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc if not token.is_space]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c7454e-d79a-4914-8c92-b76899d55ba3",
   "metadata": {},
   "source": [
    "Load Six Sentiments Lexicon for Greek Language by Drista (2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d92de9d9-0fbd-47a0-aab6-b5dba7e54920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lexicon into dictionary\n",
    "lexicon_df = pd.read_csv(\"out_lexicon_6sent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "855dd511-2b6c-466a-87df-8a002fe3ac01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>happiness</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Î±Î²Î±Ï†Ï„Î¹ÏƒÏ„Î¿Ï‚</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Î§ÏÎ¹ÏƒÏ„Î¿Ï‚</td>\n",
       "      <td>4.50</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Î±</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Î±Î²Î±Ï€Ï„Î¹ÏƒÏ„Î¿Ï‚</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Î±Î²ÎµÎ²Î±Î¹Î¿Ï„Î·Ï„Î±</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           term  anger  disgust  fear  happiness  sadness  surprise\n",
       "0   Î±Î²Î±Ï†Ï„Î¹ÏƒÏ„Î¿Ï‚    4.00     4.50  1.00        1.0     2.50      4.50\n",
       "1      Î§ÏÎ¹ÏƒÏ„Î¿Ï‚    4.50     3.75  4.25        4.0     4.00      4.50\n",
       "2            Î±    3.75     4.00  4.00        4.0     3.75      4.75\n",
       "3   Î±Î²Î±Ï€Ï„Î¹ÏƒÏ„Î¿Ï‚    4.00     4.50  1.00        1.0     2.50      4.50\n",
       "4  Î±Î²ÎµÎ²Î±Î¹Î¿Ï„Î·Ï„Î±    1.00     1.00  2.50        1.0     1.50      1.00"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19277219-775b-4e89-bf1a-478a964772d0",
   "metadata": {},
   "source": [
    "Dictionary-based sentiment lexicon constructed by mapping each term to six emotion intensity scores from the lexicon DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c986f376-a321-45e4-a1b1-d75dd5204afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = {\n",
    "    row['term'].strip(): [\n",
    "        float(row['anger']),\n",
    "        float(row['disgust']),\n",
    "        float(row['fear']),\n",
    "        float(row['happiness']),\n",
    "        float(row['sadness']),\n",
    "        float(row['surprise'])\n",
    "    ]\n",
    "    for _, row in lexicon_df.iterrows()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52440b9e-1790-42f7-b23a-ff32020c3129",
   "metadata": {},
   "source": [
    "Function defined for deriving a 6-dimensional emotion vector by averaging the RMS of emotion scores for lexicon-matched tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c226ed0-832a-4a60-a730-7d1c7b86699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent6_vec(text, lexicon, tokenize_fn):\n",
    "    word_vecs = []\n",
    "\n",
    "    for word in tokenize_fn(text):\n",
    "        if word in lexicon:\n",
    "            word_vecs.append(lexicon[word])\n",
    "\n",
    "    if not word_vecs:\n",
    "        return [0] * 6  \n",
    "    \n",
    "    word_vecs = np.array(word_vecs)\n",
    "\n",
    "    rms = np.sqrt(np.mean(np.square(word_vecs), axis=0))\n",
    "    return [round(v, 3) for v in rms]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb732ead-deb4-49e4-adbe-bf8e06e79033",
   "metadata": {},
   "source": [
    "<b style=\"color:blue;\">Test to a sample</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "79bf6c98-55f1-4f3c-902f-46bbf13cfc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = rq1_df.sample(n=1000, random_state=32).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e8e30d98-8060-4e28-a901-e6ad62676511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[1.0, 1.0, 1.0, 4.75, 1.0, 2.75]\n"
     ]
    }
   ],
   "source": [
    "print(\"Î±Î³Î±Ï€Î·Î¼ÎµÎ½Î·\" in lexicon)\n",
    "print(lexicon.get(\"Î±Î³Î±Ï€Î·Î¼ÎµÎ½Î·\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a7b083a-91a8-4cd0-9224-8ec900ff6202",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['speech_clean'] = sample_df['speech_clean'].fillna('').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5b949f14-8491-491c-8a79-5f8182114928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a101edd440434327b98ed90c893f61cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_df['sent6_vec'] = sample_df['speech_clean'].progress_apply(\n",
    "    lambda text: sent6_vec(text, lexicon, tokenize_and_lemmatize)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8cad0492-ded7-473a-a3e5-58978a3ff882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>member_name</th>\n",
       "      <th>political_party</th>\n",
       "      <th>year</th>\n",
       "      <th>roles</th>\n",
       "      <th>is_government</th>\n",
       "      <th>sent6_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318719</th>\n",
       "      <td>Î±Î½Î±Î³Î½Ï‰ÏƒÏ„Î¿Ï€Î¿Ï…Î»Î¿Ï… Ï€ÎµÏ„ÏÎ¿Ï… Î±Î¸Î±Î½Î±ÏƒÎ¹Î± (ÏƒÎ¹Î±)</td>\n",
       "      <td>ÏƒÏ…Î½Î±ÏƒÏ€Î¹ÏƒÎ¼Î¿Ï‚ ÏÎ¹Î¶Î¿ÏƒÏ€Î±ÏƒÏ„Î¹ÎºÎ·Ï‚ Î±ÏÎ¹ÏƒÏ„ÎµÏÎ±Ï‚</td>\n",
       "      <td>2019</td>\n",
       "      <td>['Î±Î½Î±Ï€Î»Î·ÏÏ‰Ï„Î·Ï‚ Ï…Ï€Î¿Ï…ÏÎ³Î¿Ï‚ ÎµÎ¾Ï‰Ï„ÎµÏÎ¹ÎºÏ‰Î½(15/02/2019-0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[3.142, 2.915, 2.016, 1.581, 1.0, 3.142]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126402</th>\n",
       "      <td>ÎºÏ‰Î½ÏƒÏ„Î±Î½Ï„Î¿Ï€Î¿Ï…Î»Î¿Ï… Î½. Î¶Ï‰Î·</td>\n",
       "      <td>ÏƒÏ…Î½Î±ÏƒÏ€Î¹ÏƒÎ¼Î¿Ï‚ ÏÎ¹Î¶Î¿ÏƒÏ€Î±ÏƒÏ„Î¹ÎºÎ·Ï‚ Î±ÏÎ¹ÏƒÏ„ÎµÏÎ±Ï‚</td>\n",
       "      <td>2014</td>\n",
       "      <td>['Î²Î¿Ï…Î»ÎµÏ…Ï„Î·Ï‚']</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321719</th>\n",
       "      <td>Î¼ÎµÎ»Î±Ï‚ Ï€Î±Î½Î±Î³Î¹Ï‰Ï„Î· Î¹Ï‰Î±Î½Î½Î·Ï‚</td>\n",
       "      <td>Î½ÎµÎ± Î´Î·Î¼Î¿ÎºÏÎ±Ï„Î¹Î±</td>\n",
       "      <td>2019</td>\n",
       "      <td>['Î²Î¿Ï…Î»ÎµÏ…Ï„Î·Ï‚']</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257082</th>\n",
       "      <td>Î²Î±ÏÎ´Î±ÎºÎ·Ï‚ Î´Î·Î¼Î·Ï„ÏÎ¹Î¿Ï… ÏƒÏ‰ÎºÏÎ±Ï„Î·Ï‚</td>\n",
       "      <td>ÏƒÏ…Î½Î±ÏƒÏ€Î¹ÏƒÎ¼Î¿Ï‚ ÏÎ¹Î¶Î¿ÏƒÏ€Î±ÏƒÏ„Î¹ÎºÎ·Ï‚ Î±ÏÎ¹ÏƒÏ„ÎµÏÎ±Ï‚</td>\n",
       "      <td>2017</td>\n",
       "      <td>['Î²Î¿Ï…Î»ÎµÏ…Ï„Î·Ï‚']</td>\n",
       "      <td>1</td>\n",
       "      <td>[2.63, 2.517, 1.744, 2.457, 1.0, 3.131]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65452</th>\n",
       "      <td>Ï‡ÏÏ…ÏƒÎ¿Ï‡Î¿Î¹Î´Î·Ï‚ Î²Î±ÏƒÎ¹Î»ÎµÎ¹Î¿Ï… Î¼Î¹Ï‡Î±Î·Î»</td>\n",
       "      <td>Ï€Î±Î½ÎµÎ»Î»Î·Î½Î¹Î¿ ÏƒÎ¿ÏƒÎ¹Î±Î»Î¹ÏƒÏ„Î¹ÎºÎ¿ ÎºÎ¹Î½Î·Î¼Î±</td>\n",
       "      <td>2012</td>\n",
       "      <td>['Ï…Ï€Î¿Ï…ÏÎ³Î¿Ï‚ Î±Î½Î±Ï€Ï„Ï…Î¾Î·Ï‚ Î±Î½Ï„Î±Î³Ï‰Î½Î¹ÏƒÏ„Î¹ÎºÎ¿Ï„Î·Ï„Î±Ï‚ ÎºÎ±Î¹ Î½Î±...</td>\n",
       "      <td>1</td>\n",
       "      <td>[3.651, 3.391, 2.363, 1.969, 1.225, 3.582]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  member_name  \\\n",
       "318719  Î±Î½Î±Î³Î½Ï‰ÏƒÏ„Î¿Ï€Î¿Ï…Î»Î¿Ï… Ï€ÎµÏ„ÏÎ¿Ï… Î±Î¸Î±Î½Î±ÏƒÎ¹Î± (ÏƒÎ¹Î±)   \n",
       "126402                 ÎºÏ‰Î½ÏƒÏ„Î±Î½Ï„Î¿Ï€Î¿Ï…Î»Î¿Ï… Î½. Î¶Ï‰Î·   \n",
       "321719                Î¼ÎµÎ»Î±Ï‚ Ï€Î±Î½Î±Î³Î¹Ï‰Ï„Î· Î¹Ï‰Î±Î½Î½Î·Ï‚   \n",
       "257082            Î²Î±ÏÎ´Î±ÎºÎ·Ï‚ Î´Î·Î¼Î·Ï„ÏÎ¹Î¿Ï… ÏƒÏ‰ÎºÏÎ±Ï„Î·Ï‚   \n",
       "65452            Ï‡ÏÏ…ÏƒÎ¿Ï‡Î¿Î¹Î´Î·Ï‚ Î²Î±ÏƒÎ¹Î»ÎµÎ¹Î¿Ï… Î¼Î¹Ï‡Î±Î·Î»   \n",
       "\n",
       "                            political_party  year  \\\n",
       "318719  ÏƒÏ…Î½Î±ÏƒÏ€Î¹ÏƒÎ¼Î¿Ï‚ ÏÎ¹Î¶Î¿ÏƒÏ€Î±ÏƒÏ„Î¹ÎºÎ·Ï‚ Î±ÏÎ¹ÏƒÏ„ÎµÏÎ±Ï‚  2019   \n",
       "126402  ÏƒÏ…Î½Î±ÏƒÏ€Î¹ÏƒÎ¼Î¿Ï‚ ÏÎ¹Î¶Î¿ÏƒÏ€Î±ÏƒÏ„Î¹ÎºÎ·Ï‚ Î±ÏÎ¹ÏƒÏ„ÎµÏÎ±Ï‚  2014   \n",
       "321719                       Î½ÎµÎ± Î´Î·Î¼Î¿ÎºÏÎ±Ï„Î¹Î±  2019   \n",
       "257082  ÏƒÏ…Î½Î±ÏƒÏ€Î¹ÏƒÎ¼Î¿Ï‚ ÏÎ¹Î¶Î¿ÏƒÏ€Î±ÏƒÏ„Î¹ÎºÎ·Ï‚ Î±ÏÎ¹ÏƒÏ„ÎµÏÎ±Ï‚  2017   \n",
       "65452        Ï€Î±Î½ÎµÎ»Î»Î·Î½Î¹Î¿ ÏƒÎ¿ÏƒÎ¹Î±Î»Î¹ÏƒÏ„Î¹ÎºÎ¿ ÎºÎ¹Î½Î·Î¼Î±  2012   \n",
       "\n",
       "                                                    roles  is_government  \\\n",
       "318719  ['Î±Î½Î±Ï€Î»Î·ÏÏ‰Ï„Î·Ï‚ Ï…Ï€Î¿Ï…ÏÎ³Î¿Ï‚ ÎµÎ¾Ï‰Ï„ÎµÏÎ¹ÎºÏ‰Î½(15/02/2019-0...              0   \n",
       "126402                                      ['Î²Î¿Ï…Î»ÎµÏ…Ï„Î·Ï‚']              0   \n",
       "321719                                      ['Î²Î¿Ï…Î»ÎµÏ…Ï„Î·Ï‚']              0   \n",
       "257082                                      ['Î²Î¿Ï…Î»ÎµÏ…Ï„Î·Ï‚']              1   \n",
       "65452   ['Ï…Ï€Î¿Ï…ÏÎ³Î¿Ï‚ Î±Î½Î±Ï€Ï„Ï…Î¾Î·Ï‚ Î±Î½Ï„Î±Î³Ï‰Î½Î¹ÏƒÏ„Î¹ÎºÎ¿Ï„Î·Ï„Î±Ï‚ ÎºÎ±Î¹ Î½Î±...              1   \n",
       "\n",
       "                                         sent6_vec  \n",
       "318719    [3.142, 2.915, 2.016, 1.581, 1.0, 3.142]  \n",
       "126402                          [0, 0, 0, 0, 0, 0]  \n",
       "321719                          [0, 0, 0, 0, 0, 0]  \n",
       "257082     [2.63, 2.517, 1.744, 2.457, 1.0, 3.131]  \n",
       "65452   [3.651, 3.391, 2.363, 1.969, 1.225, 3.582]  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df[['member_name', 'political_party', 'year', 'roles', 'is_government', 'sent6_vec']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aff5927c-0cfe-43d2-8c18-81c2c20d6b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_cols = ['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise']\n",
    "sentiment_df = pd.DataFrame(sample_df['sent6_vec'].tolist(), columns=sentiment_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f8c6bfd1-2e9f-4038-897d-a10ee208f42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_sent = pd.concat([sample_df, sentiment_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1bd87741-14ca-4449-8a58-ab4773135ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>happiness</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.769585</td>\n",
       "      <td>1.588783</td>\n",
       "      <td>1.115906</td>\n",
       "      <td>1.067624</td>\n",
       "      <td>0.714237</td>\n",
       "      <td>1.915119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.644246</td>\n",
       "      <td>1.505850</td>\n",
       "      <td>1.040254</td>\n",
       "      <td>0.995051</td>\n",
       "      <td>0.668034</td>\n",
       "      <td>1.727340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.261000</td>\n",
       "      <td>3.026000</td>\n",
       "      <td>2.109000</td>\n",
       "      <td>1.969000</td>\n",
       "      <td>1.145000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.330000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.330000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             anger      disgust         fear    happiness      sadness  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      1.769585     1.588783     1.115906     1.067624     0.714237   \n",
       "std       1.644246     1.505850     1.040254     0.995051     0.668034   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       2.000000     1.500000     1.000000     1.000000     1.000000   \n",
       "75%       3.261000     3.026000     2.109000     1.969000     1.145000   \n",
       "max       4.330000     4.000000     4.250000     4.500000     3.500000   \n",
       "\n",
       "          surprise  \n",
       "count  1000.000000  \n",
       "mean      1.915119  \n",
       "std       1.727340  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       2.500000  \n",
       "75%       3.500000  \n",
       "max       4.330000  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df_sent[sentiment_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dad330-8145-492e-9eb2-f702ea273ef2",
   "metadata": {},
   "source": [
    "6-dimensional emotion vectors computed for all cleaned speeches using the defined function and stored in a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d196cc6d-f4bb-4dd4-afb8-57da03dc0f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4801d9492ed049c8989ae61a4bffa82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/341805 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rq1_df['sent6_vec'] = rq1_df['speech_clean'].progress_apply(\n",
    "    lambda text: sent6_vec(text, lexicon, tokenize_and_lemmatize)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2362eac-e683-4740-bf40-7adf0b1c678e",
   "metadata": {},
   "source": [
    "Emotion vector results stored in a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "52da6789-d5b9-403a-9f06-90fb61cf5460",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_cols = ['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise']\n",
    "sentiment_redf = pd.DataFrame(rq1_df['sent6_vec'].tolist(), columns=sentiment_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0215d899-e0f9-44c5-b858-a499abc0fd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cols = ['member_name', 'political_party', 'year', 'is_government', 'roles']\n",
    "meta_df = rq1_df[meta_cols].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d73b2bd8-90fb-4c28-8c0e-060291fce77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rq1_results_df = pd.concat([meta_df, sentiment_redf], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (proceedings-asds2)",
   "language": "python",
   "name": "proceedings-asds2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
